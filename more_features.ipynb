{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import FeatureHasher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>building_id</th>\n",
       "      <th>created</th>\n",
       "      <th>description</th>\n",
       "      <th>display_address</th>\n",
       "      <th>features</th>\n",
       "      <th>interest_level</th>\n",
       "      <th>latitude</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>longitude</th>\n",
       "      <th>manager_id</th>\n",
       "      <th>photos</th>\n",
       "      <th>price</th>\n",
       "      <th>street_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>53a5b119ba8f7b61d4e010512e0dfc85</td>\n",
       "      <td>2016-06-24 07:54:24</td>\n",
       "      <td>A Brand New 3 Bedroom 1.5 bath ApartmentEnjoy ...</td>\n",
       "      <td>Metropolitan Avenue</td>\n",
       "      <td>[]</td>\n",
       "      <td>medium</td>\n",
       "      <td>40.7145</td>\n",
       "      <td>7211212</td>\n",
       "      <td>-73.9425</td>\n",
       "      <td>5ba989232d0489da1b5f2c45f6688adc</td>\n",
       "      <td>[https://photos.renthop.com/2/7211212_1ed4542e...</td>\n",
       "      <td>3000</td>\n",
       "      <td>792 Metropolitan Avenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>c5c8a357cba207596b04d1afd1e4f130</td>\n",
       "      <td>2016-06-12 12:19:27</td>\n",
       "      <td></td>\n",
       "      <td>Columbus Avenue</td>\n",
       "      <td>[Doorman, Elevator, Fitness Center, Cats Allow...</td>\n",
       "      <td>low</td>\n",
       "      <td>40.7947</td>\n",
       "      <td>7150865</td>\n",
       "      <td>-73.9667</td>\n",
       "      <td>7533621a882f71e25173b27e3139d83d</td>\n",
       "      <td>[https://photos.renthop.com/2/7150865_be3306c5...</td>\n",
       "      <td>5465</td>\n",
       "      <td>808 Columbus Avenue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         bathrooms  bedrooms                       building_id  \\\n",
       "10.0           1.5         3  53a5b119ba8f7b61d4e010512e0dfc85   \n",
       "10000.0        1.0         2  c5c8a357cba207596b04d1afd1e4f130   \n",
       "\n",
       "                     created  \\\n",
       "10.0     2016-06-24 07:54:24   \n",
       "10000.0  2016-06-12 12:19:27   \n",
       "\n",
       "                                               description  \\\n",
       "10.0     A Brand New 3 Bedroom 1.5 bath ApartmentEnjoy ...   \n",
       "10000.0                                                      \n",
       "\n",
       "             display_address  \\\n",
       "10.0     Metropolitan Avenue   \n",
       "10000.0      Columbus Avenue   \n",
       "\n",
       "                                                  features interest_level  \\\n",
       "10.0                                                    []         medium   \n",
       "10000.0  [Doorman, Elevator, Fitness Center, Cats Allow...            low   \n",
       "\n",
       "         latitude  listing_id  longitude                        manager_id  \\\n",
       "10.0      40.7145     7211212   -73.9425  5ba989232d0489da1b5f2c45f6688adc   \n",
       "10000.0   40.7947     7150865   -73.9667  7533621a882f71e25173b27e3139d83d   \n",
       "\n",
       "                                                    photos  price  \\\n",
       "10.0     [https://photos.renthop.com/2/7211212_1ed4542e...   3000   \n",
       "10000.0  [https://photos.renthop.com/2/7150865_be3306c5...   5465   \n",
       "\n",
       "                  street_address  \n",
       "10.0     792 Metropolitan Avenue  \n",
       "10000.0      808 Columbus Avenue  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train = pd.read_json('input/train.json', orient='columns')\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- start with bath, beds, manager id, build id, price\n",
    "- transform manager id and building id into average interest level\n",
    "- standardize inputs\n",
    "- split into train/validation stratfied\n",
    "- take sample from both train and validation\n",
    "- train lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createSamples(X_train, y_train, X_test, y_test, num_train= 1000, num_test=400):\n",
    "    \n",
    "    nums = np.arange(X_train.shape[0])\n",
    "    np.random.shuffle(nums)\n",
    "    X_train_samp = X_train.iloc[nums[:num_train]]\n",
    "    y_train_samp = y_train.iloc[nums[:num_train]]\n",
    "\n",
    "\n",
    "    test_nums = np.arange(X_test.shape[0])\n",
    "    np.random.shuffle(test_nums)\n",
    "\n",
    "    X_test_samp = X_test.iloc[test_nums[:num_test]]\n",
    "    y_test_samp = y_test.iloc[test_nums[:num_test]]\n",
    "    return X_train_samp, y_train_samp, X_test_samp, y_test_samp\n",
    "\n",
    "def get_accuracy(preds, y_test_samp):\n",
    "    return (preds == y_test_samp).sum() / preds.shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def subAndSample(subset, num_train=20000, num_test=2000, comp=False):\n",
    "    X = subset.drop('enc_interest', axis=1)\n",
    "    y = subset.enc_interest\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "    if comp:\n",
    "        return X_train, y_train, X_test, y_test \n",
    "    else:\n",
    "        return createSamples(X_train, y_train, X_test, y_test, num_train=num_train, num_test=num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def standardize(X_train, X_test):\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(X_train)\n",
    "    X_train = sc.transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['enc_interest'] = train.interest_level.map({'low': 0, 'medium': 1, 'high':2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## only baths, beds, price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subset = train[['bathrooms', 'bedrooms', 'price', 'enc_interest']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.299891\tval-merror:0.300375\n",
      "[1]\ttrain-merror:0.29903\tval-merror:0.299767\n",
      "[2]\ttrain-merror:0.298574\tval-merror:0.298855\n",
      "[3]\ttrain-merror:0.298574\tval-merror:0.298855\n",
      "[4]\ttrain-merror:0.298321\tval-merror:0.298754\n",
      "[5]\ttrain-merror:0.298169\tval-merror:0.298754\n",
      "[6]\ttrain-merror:0.298067\tval-merror:0.298754\n",
      "[7]\ttrain-merror:0.297915\tval-merror:0.298247\n",
      "[8]\ttrain-merror:0.297865\tval-merror:0.298349\n",
      "[9]\ttrain-merror:0.297688\tval-merror:0.298146\n",
      "[10]\ttrain-merror:0.297839\tval-merror:0.298349\n",
      "[11]\ttrain-merror:0.297839\tval-merror:0.298349\n",
      "[12]\ttrain-merror:0.297839\tval-merror:0.298551\n",
      "[13]\ttrain-merror:0.297814\tval-merror:0.298349\n",
      "[14]\ttrain-merror:0.297839\tval-merror:0.298551\n",
      "[15]\ttrain-merror:0.297789\tval-merror:0.298653\n",
      "[16]\ttrain-merror:0.297789\tval-merror:0.298551\n",
      "[17]\ttrain-merror:0.297789\tval-merror:0.298551\n",
      "[18]\ttrain-merror:0.297561\tval-merror:0.298653\n",
      "[19]\ttrain-merror:0.297561\tval-merror:0.298653\n",
      "val loss  0.698312317973\n",
      "[0]\ttrain-merror:0.299258\tval-merror:0.300983\n",
      "[1]\ttrain-merror:0.299258\tval-merror:0.300881\n",
      "[2]\ttrain-merror:0.298878\tval-merror:0.300274\n",
      "[3]\ttrain-merror:0.298853\tval-merror:0.300274\n",
      "[4]\ttrain-merror:0.29865\tval-merror:0.299868\n",
      "[5]\ttrain-merror:0.298321\tval-merror:0.299666\n",
      "[6]\ttrain-merror:0.297814\tval-merror:0.299666\n",
      "[7]\ttrain-merror:0.297789\tval-merror:0.299868\n",
      "[8]\ttrain-merror:0.298321\tval-merror:0.300172\n",
      "[9]\ttrain-merror:0.298321\tval-merror:0.300172\n",
      "[10]\ttrain-merror:0.298143\tval-merror:0.300071\n",
      "[11]\ttrain-merror:0.298143\tval-merror:0.300172\n",
      "[12]\ttrain-merror:0.298143\tval-merror:0.300172\n",
      "[13]\ttrain-merror:0.297738\tval-merror:0.300172\n",
      "[14]\ttrain-merror:0.297637\tval-merror:0.300071\n",
      "[15]\ttrain-merror:0.297586\tval-merror:0.300071\n",
      "[16]\ttrain-merror:0.297029\tval-merror:0.299058\n",
      "[17]\ttrain-merror:0.296902\tval-merror:0.298957\n",
      "[18]\ttrain-merror:0.296928\tval-merror:0.298957\n",
      "[19]\ttrain-merror:0.296902\tval-merror:0.298957\n",
      "val loss  0.703411067842\n",
      "[0]\ttrain-merror:0.299461\tval-merror:0.300983\n",
      "[1]\ttrain-merror:0.298523\tval-merror:0.299868\n",
      "[2]\ttrain-merror:0.29827\tval-merror:0.299666\n",
      "[3]\ttrain-merror:0.298245\tval-merror:0.299666\n",
      "[4]\ttrain-merror:0.298093\tval-merror:0.299564\n",
      "[5]\ttrain-merror:0.298143\tval-merror:0.300274\n",
      "[6]\ttrain-merror:0.298143\tval-merror:0.300274\n",
      "[7]\ttrain-merror:0.298169\tval-merror:0.299564\n",
      "[8]\ttrain-merror:0.298093\tval-merror:0.300274\n",
      "[9]\ttrain-merror:0.298118\tval-merror:0.300274\n",
      "[10]\ttrain-merror:0.297915\tval-merror:0.299463\n",
      "[11]\ttrain-merror:0.297915\tval-merror:0.299463\n",
      "[12]\ttrain-merror:0.297991\tval-merror:0.299463\n",
      "[13]\ttrain-merror:0.297991\tval-merror:0.299463\n",
      "[14]\ttrain-merror:0.297333\tval-merror:0.299159\n",
      "[15]\ttrain-merror:0.297308\tval-merror:0.298754\n",
      "[16]\ttrain-merror:0.296902\tval-merror:0.299666\n",
      "[17]\ttrain-merror:0.296902\tval-merror:0.299666\n",
      "[18]\ttrain-merror:0.296852\tval-merror:0.299868\n",
      "[19]\ttrain-merror:0.296801\tval-merror:0.299362\n",
      "val loss  0.694698998877\n",
      "avg val loss 0.694698998877\n",
      "avg train loss 0.690716023026\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    val_losses = np.array([])\n",
    "    train_losses = np.array([])\n",
    "    X_train, y_train, X_test, y_test = subAndSample(subset, comp=True)\n",
    "\n",
    "    X_train, X_test = standardize(X_train, X_test)\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, label= y_train)\n",
    "    dval = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "    # specify parameters via map\n",
    "    watchlist = [(dtrain,'train'), (dval,'val')]\n",
    "    param = {'max_depth':3, 'eta':1, 'silent':1, 'num_class': 3, 'objective':'multi:softprob' }\n",
    "    num_round = 20\n",
    "    bst = xgb.train(param, dtrain, num_round, watchlist)\n",
    "    preds = bst.predict(dval)\n",
    "    val_loss = log_loss(y_test, preds)\n",
    "    print('val loss ',val_loss)\n",
    "    train_loss = log_loss(y_train, bst.predict(dtrain))\n",
    "    train_losses = np.append(train_losses, train_loss)\n",
    "    val_losses = np.append(val_losses, val_loss)\n",
    "print('avg val loss', np.mean(val_losses))\n",
    "print('avg train loss', np.mean(train_losses))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lat Long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subset= train[['bathrooms', 'bedrooms', 'price','enc_interest', 'latitude', 'longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.29984\tval-merror:0.300476\n",
      "[1]\ttrain-merror:0.298295\tval-merror:0.300881\n",
      "[2]\ttrain-merror:0.29746\tval-merror:0.301185\n",
      "[3]\ttrain-merror:0.293787\tval-merror:0.299159\n",
      "[4]\ttrain-merror:0.292672\tval-merror:0.29764\n",
      "[5]\ttrain-merror:0.292571\tval-merror:0.296728\n",
      "[6]\ttrain-merror:0.29095\tval-merror:0.298045\n",
      "[7]\ttrain-merror:0.290266\tval-merror:0.295512\n",
      "[8]\ttrain-merror:0.288949\tval-merror:0.296019\n",
      "[9]\ttrain-merror:0.287151\tval-merror:0.295917\n",
      "[10]\ttrain-merror:0.285707\tval-merror:0.295715\n",
      "[11]\ttrain-merror:0.285175\tval-merror:0.296728\n",
      "[12]\ttrain-merror:0.284795\tval-merror:0.296424\n",
      "[13]\ttrain-merror:0.283934\tval-merror:0.2946\n",
      "[14]\ttrain-merror:0.283655\tval-merror:0.294195\n",
      "[15]\ttrain-merror:0.283554\tval-merror:0.2946\n",
      "[16]\ttrain-merror:0.28325\tval-merror:0.294296\n",
      "[17]\ttrain-merror:0.283048\tval-merror:0.294398\n",
      "[18]\ttrain-merror:0.282186\tval-merror:0.294094\n",
      "[19]\ttrain-merror:0.281882\tval-merror:0.293891\n",
      "val loss  0.674933778821\n",
      "[0]\ttrain-merror:0.299916\tval-merror:0.300375\n",
      "[1]\ttrain-merror:0.298245\tval-merror:0.299767\n",
      "[2]\ttrain-merror:0.298447\tval-merror:0.299666\n",
      "[3]\ttrain-merror:0.297662\tval-merror:0.299362\n",
      "[4]\ttrain-merror:0.294699\tval-merror:0.295006\n",
      "[5]\ttrain-merror:0.292166\tval-merror:0.293587\n",
      "[6]\ttrain-merror:0.291761\tval-merror:0.29379\n",
      "[7]\ttrain-merror:0.291381\tval-merror:0.291359\n",
      "[8]\ttrain-merror:0.29095\tval-merror:0.290244\n",
      "[9]\ttrain-merror:0.288519\tval-merror:0.289028\n",
      "[10]\ttrain-merror:0.288088\tval-merror:0.291359\n",
      "[11]\ttrain-merror:0.287556\tval-merror:0.29146\n",
      "[12]\ttrain-merror:0.286366\tval-merror:0.289535\n",
      "[13]\ttrain-merror:0.285504\tval-merror:0.290953\n",
      "[14]\ttrain-merror:0.285226\tval-merror:0.290447\n",
      "[15]\ttrain-merror:0.284871\tval-merror:0.291055\n",
      "[16]\ttrain-merror:0.283858\tval-merror:0.289332\n",
      "[17]\ttrain-merror:0.283124\tval-merror:0.287813\n",
      "[18]\ttrain-merror:0.282693\tval-merror:0.286496\n",
      "[19]\ttrain-merror:0.281452\tval-merror:0.286394\n",
      "val loss  0.658521177948\n",
      "[0]\ttrain-merror:0.298397\tval-merror:0.299767\n",
      "[1]\ttrain-merror:0.297434\tval-merror:0.29926\n",
      "[2]\ttrain-merror:0.296953\tval-merror:0.298551\n",
      "[3]\ttrain-merror:0.295155\tval-merror:0.29764\n",
      "[4]\ttrain-merror:0.294319\tval-merror:0.297032\n",
      "[5]\ttrain-merror:0.291279\tval-merror:0.298754\n",
      "[6]\ttrain-merror:0.290671\tval-merror:0.297538\n",
      "[7]\ttrain-merror:0.289836\tval-merror:0.296728\n",
      "[8]\ttrain-merror:0.28862\tval-merror:0.296221\n",
      "[9]\ttrain-merror:0.288873\tval-merror:0.296525\n",
      "[10]\ttrain-merror:0.287708\tval-merror:0.29612\n",
      "[11]\ttrain-merror:0.286568\tval-merror:0.297032\n",
      "[12]\ttrain-merror:0.284998\tval-merror:0.296525\n",
      "[13]\ttrain-merror:0.283757\tval-merror:0.296323\n",
      "[14]\ttrain-merror:0.284314\tval-merror:0.296424\n",
      "[15]\ttrain-merror:0.283022\tval-merror:0.296221\n",
      "[16]\ttrain-merror:0.282896\tval-merror:0.29612\n",
      "[17]\ttrain-merror:0.282769\tval-merror:0.29693\n",
      "[18]\ttrain-merror:0.282262\tval-merror:0.295715\n",
      "[19]\ttrain-merror:0.281806\tval-merror:0.294195\n",
      "val loss  0.668641789143\n",
      "avg val loss 0.668641789143\n",
      "avg train loss 0.649742551929\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    val_losses = np.array([])\n",
    "    train_losses = np.array([])\n",
    "    X_train, y_train, X_test, y_test = subAndSample(subset, comp=True)\n",
    "\n",
    "    X_train, X_test = standardize(X_train, X_test)\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, label= y_train)\n",
    "    dval = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "    # specify parameters via map\n",
    "    watchlist = [(dtrain,'train'), (dval,'val')]\n",
    "    param = {'max_depth':3, 'eta':1, 'silent':1, 'num_class': 3, 'objective':'multi:softprob' }\n",
    "    num_round = 20\n",
    "    bst = xgb.train(param, dtrain, num_round, watchlist)\n",
    "    preds = bst.predict(dval)\n",
    "    val_loss = log_loss(y_test, preds)\n",
    "    print('val loss ',val_loss)\n",
    "    train_loss = log_loss(y_train, bst.predict(dtrain))\n",
    "    train_losses = np.append(train_losses, train_loss)\n",
    "    val_losses = np.append(val_losses, val_loss)\n",
    "print('avg val loss', np.mean(val_losses))\n",
    "print('avg train loss', np.mean(train_losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## building_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.296294\tval-merror:0.297741\n",
      "[1]\ttrain-merror:0.29323\tval-merror:0.297538\n",
      "[2]\ttrain-merror:0.292115\tval-merror:0.296626\n",
      "[3]\ttrain-merror:0.289886\tval-merror:0.295512\n",
      "[4]\ttrain-merror:0.292191\tval-merror:0.29764\n",
      "[5]\ttrain-merror:0.291659\tval-merror:0.296221\n",
      "[6]\ttrain-merror:0.289633\tval-merror:0.294702\n",
      "[7]\ttrain-merror:0.289253\tval-merror:0.2946\n",
      "[8]\ttrain-merror:0.288443\tval-merror:0.293283\n",
      "[9]\ttrain-merror:0.288113\tval-merror:0.293385\n",
      "[10]\ttrain-merror:0.287505\tval-merror:0.29612\n",
      "[11]\ttrain-merror:0.286771\tval-merror:0.295512\n",
      "[12]\ttrain-merror:0.285555\tval-merror:0.296019\n",
      "[13]\ttrain-merror:0.285023\tval-merror:0.295309\n",
      "[14]\ttrain-merror:0.284061\tval-merror:0.294499\n",
      "[15]\ttrain-merror:0.284441\tval-merror:0.293689\n",
      "[16]\ttrain-merror:0.283807\tval-merror:0.29379\n",
      "[17]\ttrain-merror:0.283225\tval-merror:0.294398\n",
      "[18]\ttrain-merror:0.282516\tval-merror:0.294296\n",
      "[19]\ttrain-merror:0.28282\tval-merror:0.293992\n"
     ]
    }
   ],
   "source": [
    "subset= train[['bathrooms', 'bedrooms', 'price','enc_interest', 'building_id']]\n",
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test = subAndSample(subset, comp=True)\n",
    "h = FeatureHasher(input_type='string')\n",
    "\n",
    "hashed = h.fit_transform(X_train.building_id)\n",
    "\n",
    "\n",
    "test_hashed = h.transform(X_test.building_id)\n",
    "\n",
    "X_train = X_train.drop('building_id', axis=1)\n",
    "X_test = X_test.drop('building_id', axis=1)\n",
    "\n",
    "X_train[['bathrooms', 'bedrooms', 'price']], X_test[['bathrooms', 'bedrooms', 'price']] =\\\n",
    "standardize(X_train[['bathrooms', 'bedrooms', 'price']],\\\n",
    "            X_test[['bathrooms', 'bedrooms', 'price']])\n",
    "\n",
    "X_train_concat = scipy.sparse.hstack((X_train,hashed))\n",
    "\n",
    "X_test_concat = scipy.sparse.hstack((X_test, test_hashed))\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train_concat, label= y_train)\n",
    "dval = xgb.DMatrix(X_test_concat, label=y_test)\n",
    "\n",
    "# specify parameters via map\n",
    "watchlist = [(dtrain,'train'), (dval,'val')]\n",
    "param = {'max_depth':3, 'eta':1, 'silent':1, 'num_class': 3, 'objective':'multi:softprob' }\n",
    "num_round = 20\n",
    "bst = xgb.train(param, dtrain, num_round, watchlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.657810807608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.64327181387724686"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = bst.predict(dval)\n",
    "print(log_loss(y_test, preds))\n",
    "log_loss(y_train, bst.predict(dtrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another run to check if improvement holds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.655097364907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.64457443448196794"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = bst.predict(dval)\n",
    "print(log_loss(y_test, preds))\n",
    "log_loss(y_train, bst.predict(dtrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manager Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.299385\tval-merror:0.300476\n",
      "[1]\ttrain-merror:0.299005\tval-merror:0.299362\n",
      "[2]\ttrain-merror:0.298802\tval-merror:0.300172\n",
      "[3]\ttrain-merror:0.29594\tval-merror:0.29764\n",
      "[4]\ttrain-merror:0.296066\tval-merror:0.300983\n",
      "[5]\ttrain-merror:0.295104\tval-merror:0.300577\n",
      "[6]\ttrain-merror:0.294673\tval-merror:0.298754\n",
      "[7]\ttrain-merror:0.293762\tval-merror:0.298247\n",
      "[8]\ttrain-merror:0.29247\tval-merror:0.298653\n",
      "[9]\ttrain-merror:0.291558\tval-merror:0.29693\n",
      "[10]\ttrain-merror:0.291001\tval-merror:0.29764\n",
      "[11]\ttrain-merror:0.291102\tval-merror:0.297336\n",
      "[12]\ttrain-merror:0.289861\tval-merror:0.297842\n",
      "[13]\ttrain-merror:0.288974\tval-merror:0.29764\n",
      "[14]\ttrain-merror:0.288291\tval-merror:0.296221\n",
      "[15]\ttrain-merror:0.287835\tval-merror:0.295208\n",
      "[16]\ttrain-merror:0.287227\tval-merror:0.292878\n",
      "[17]\ttrain-merror:0.28596\tval-merror:0.294904\n",
      "[18]\ttrain-merror:0.285707\tval-merror:0.294398\n",
      "[19]\ttrain-merror:0.285049\tval-merror:0.292473\n"
     ]
    }
   ],
   "source": [
    "subset= train[['bathrooms', 'bedrooms', 'price','enc_interest', 'manager_id']]\n",
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test = subAndSample(subset, comp=True)\n",
    "h = FeatureHasher(input_type='string')\n",
    "\n",
    "hashed = h.fit_transform(X_train.manager_id)\n",
    "\n",
    "\n",
    "test_hashed = h.transform(X_test.manager_id)\n",
    "\n",
    "X_train = X_train.drop('manager_id', axis=1)\n",
    "X_test = X_test.drop('manager_id', axis=1)\n",
    "\n",
    "X_train[['bathrooms', 'bedrooms', 'price']], X_test[['bathrooms', 'bedrooms', 'price']] =\\\n",
    "standardize(X_train[['bathrooms', 'bedrooms', 'price']],\\\n",
    "            X_test[['bathrooms', 'bedrooms', 'price']])\n",
    "\n",
    "X_train_concat = scipy.sparse.hstack((X_train,hashed))\n",
    "\n",
    "X_test_concat = scipy.sparse.hstack((X_test, test_hashed))\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train_concat, label= y_train)\n",
    "dval = xgb.DMatrix(X_test_concat, label=y_test)\n",
    "\n",
    "# specify parameters via map\n",
    "watchlist = [(dtrain,'train'), (dval,'val')]\n",
    "param = {'max_depth':3, 'eta':1, 'silent':1, 'num_class': 3, 'objective':'multi:softprob' }\n",
    "num_round = 20\n",
    "bst = xgb.train(param, dtrain, num_round, watchlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.668980750305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6517843306251726"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = bst.predict(dval)\n",
    "print(log_loss(y_test, preds))\n",
    "log_loss(y_train, bst.predict(dtrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.676009044779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.65369270005257252"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = bst.predict(dval)\n",
    "print(log_loss(y_test, preds))\n",
    "log_loss(y_train, bst.predict(dtrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['created'] = pd.to_datetime(train.created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['year'] = train.created.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['month'] = train.created.dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['hour'] = train.created.dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 4, 5])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.month.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month\n",
       "4    0.385412\n",
       "5    0.386656\n",
       "6    0.377625\n",
       "Name: enc_interest, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('month').enc_interest.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hour\n",
       "0     0.727273\n",
       "1     0.109062\n",
       "2     0.339656\n",
       "3     0.328925\n",
       "4     0.350129\n",
       "5     0.492960\n",
       "6     0.508097\n",
       "7     0.412607\n",
       "8     0.440476\n",
       "9     0.651852\n",
       "10    0.595070\n",
       "11    0.515766\n",
       "12    0.575758\n",
       "13    0.551948\n",
       "14    0.517903\n",
       "15    0.577689\n",
       "16    0.613514\n",
       "17    0.641084\n",
       "18    0.531111\n",
       "19    0.590226\n",
       "20    0.654450\n",
       "21    0.691011\n",
       "22    0.733813\n",
       "23    0.755814\n",
       "Name: enc_interest, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('hour').enc_interest.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hour\n",
       "0        55\n",
       "1      5749\n",
       "2     10596\n",
       "3      8318\n",
       "4      5021\n",
       "5      7954\n",
       "6      4446\n",
       "7      1047\n",
       "8       336\n",
       "9       135\n",
       "10      284\n",
       "11      444\n",
       "12      693\n",
       "13      616\n",
       "14      782\n",
       "15      753\n",
       "16      370\n",
       "17      443\n",
       "18      450\n",
       "19      266\n",
       "20      191\n",
       "21      178\n",
       "22      139\n",
       "23       86\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('hour').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subset = train[['bathrooms', 'hour', 'bedrooms', 'price', 'enc_interest']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.299435\tval-merror:0.299666\n",
      "[1]\ttrain-merror:0.296978\tval-merror:0.297943\n",
      "[2]\ttrain-merror:0.296725\tval-merror:0.297437\n",
      "[3]\ttrain-merror:0.297915\tval-merror:0.298146\n",
      "[4]\ttrain-merror:0.29599\tval-merror:0.297032\n",
      "[5]\ttrain-merror:0.295383\tval-merror:0.296323\n",
      "[6]\ttrain-merror:0.2948\tval-merror:0.29612\n",
      "[7]\ttrain-merror:0.294547\tval-merror:0.295411\n",
      "[8]\ttrain-merror:0.293584\tval-merror:0.295512\n",
      "[9]\ttrain-merror:0.293483\tval-merror:0.295613\n",
      "[10]\ttrain-merror:0.292596\tval-merror:0.295411\n",
      "[11]\ttrain-merror:0.29209\tval-merror:0.295512\n",
      "[12]\ttrain-merror:0.291786\tval-merror:0.295208\n",
      "[13]\ttrain-merror:0.290722\tval-merror:0.293486\n",
      "[14]\ttrain-merror:0.29057\tval-merror:0.293587\n",
      "[15]\ttrain-merror:0.290342\tval-merror:0.292169\n",
      "[16]\ttrain-merror:0.290469\tval-merror:0.292676\n",
      "[17]\ttrain-merror:0.290089\tval-merror:0.292169\n",
      "[18]\ttrain-merror:0.289785\tval-merror:0.292574\n",
      "[19]\ttrain-merror:0.289734\tval-merror:0.293081\n",
      "val loss  0.668875213023\n",
      "[0]\ttrain-merror:0.298473\tval-merror:0.298247\n",
      "[1]\ttrain-merror:0.298878\tval-merror:0.298247\n",
      "[2]\ttrain-merror:0.297814\tval-merror:0.296525\n",
      "[3]\ttrain-merror:0.298245\tval-merror:0.297234\n",
      "[4]\ttrain-merror:0.295357\tval-merror:0.29379\n",
      "[5]\ttrain-merror:0.2948\tval-merror:0.293385\n",
      "[6]\ttrain-merror:0.295281\tval-merror:0.292676\n",
      "[7]\ttrain-merror:0.294673\tval-merror:0.292473\n",
      "[8]\ttrain-merror:0.294445\tval-merror:0.291662\n",
      "[9]\ttrain-merror:0.294192\tval-merror:0.29146\n",
      "[10]\ttrain-merror:0.294217\tval-merror:0.292068\n",
      "[11]\ttrain-merror:0.294116\tval-merror:0.291662\n",
      "[12]\ttrain-merror:0.29247\tval-merror:0.290751\n",
      "[13]\ttrain-merror:0.291989\tval-merror:0.290852\n",
      "[14]\ttrain-merror:0.292065\tval-merror:0.290649\n",
      "[15]\ttrain-merror:0.291786\tval-merror:0.290852\n",
      "[16]\ttrain-merror:0.291659\tval-merror:0.290751\n",
      "[17]\ttrain-merror:0.291051\tval-merror:0.290244\n",
      "[18]\ttrain-merror:0.290671\tval-merror:0.290345\n",
      "[19]\ttrain-merror:0.290418\tval-merror:0.291257\n",
      "val loss  0.669714533796\n",
      "[0]\ttrain-merror:0.299283\tval-merror:0.300274\n",
      "[1]\ttrain-merror:0.296725\tval-merror:0.299058\n",
      "[2]\ttrain-merror:0.296345\tval-merror:0.298855\n",
      "[3]\ttrain-merror:0.29518\tval-merror:0.29764\n",
      "[4]\ttrain-merror:0.293534\tval-merror:0.2946\n",
      "[5]\ttrain-merror:0.292774\tval-merror:0.295006\n",
      "[6]\ttrain-merror:0.292571\tval-merror:0.294904\n",
      "[7]\ttrain-merror:0.292571\tval-merror:0.294499\n",
      "[8]\ttrain-merror:0.293179\tval-merror:0.295006\n",
      "[9]\ttrain-merror:0.292723\tval-merror:0.293486\n",
      "[10]\ttrain-merror:0.292622\tval-merror:0.293081\n",
      "[11]\ttrain-merror:0.291837\tval-merror:0.292777\n",
      "[12]\ttrain-merror:0.291735\tval-merror:0.293283\n",
      "[13]\ttrain-merror:0.290975\tval-merror:0.292372\n",
      "[14]\ttrain-merror:0.290697\tval-merror:0.292878\n",
      "[15]\ttrain-merror:0.290874\tval-merror:0.292979\n",
      "[16]\ttrain-merror:0.291051\tval-merror:0.293182\n",
      "[17]\ttrain-merror:0.291077\tval-merror:0.293182\n",
      "[18]\ttrain-merror:0.290874\tval-merror:0.292878\n",
      "[19]\ttrain-merror:0.290064\tval-merror:0.295107\n",
      "val loss  0.675030794075\n",
      "avg val loss 0.675030794075\n",
      "avg train loss 0.658991394056\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    val_losses = np.array([])\n",
    "    train_losses = np.array([])\n",
    "    X_train, y_train, X_test, y_test = subAndSample(subset, comp=True)\n",
    "\n",
    "    X_train[['bathrooms', 'hour', 'bedrooms', 'price']], X_test[['bathrooms', 'hour', 'bedrooms', 'price']] =\\\n",
    "    standardize(X_train[['bathrooms', 'hour', 'bedrooms', 'price']], \n",
    "                X_test[['bathrooms', 'hour', 'bedrooms', 'price']])\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, label= y_train)\n",
    "    dval = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "    # specify parameters via map\n",
    "    watchlist = [(dtrain,'train'), (dval,'val')]\n",
    "    param = {'max_depth':3, 'eta':1, 'silent':1, 'num_class': 3, 'objective':'multi:softprob' }\n",
    "    num_round = 20\n",
    "    bst = xgb.train(param, dtrain, num_round, watchlist)\n",
    "    preds = bst.predict(dval)\n",
    "    val_loss = log_loss(y_test, preds)\n",
    "    print('val loss ',val_loss)\n",
    "    train_loss = log_loss(y_train, bst.predict(dtrain))\n",
    "    train_losses = np.append(train_losses, train_loss)\n",
    "    val_losses = np.append(val_losses, val_loss)\n",
    "print('avg val loss', np.mean(val_losses))\n",
    "print('avg train loss', np.mean(train_losses))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['num_photos'] = train.photos.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enc_interest\n",
       "0    5.524647\n",
       "1    5.813251\n",
       "2    5.738474\n",
       "Name: num_photos, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('enc_interest').num_photos.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13cd0d710>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAERCAYAAAB8eMxzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhfn/zZMEp94AEMAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13c9e2dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data=train, x='enc_interest', y='num_photos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['no_photos'] = train.num_photos == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['no_photos'] = train.no_photos.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.061687413554633475"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.num_photos == 0].enc_interest.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subset = train[['bathrooms', 'bedrooms', 'price', 'num_photos', 'no_photos', 'enc_interest']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.299562\tval-merror:0.30078\n",
      "[1]\ttrain-merror:0.29746\tval-merror:0.300476\n",
      "[2]\ttrain-merror:0.297232\tval-merror:0.300881\n",
      "[3]\ttrain-merror:0.29708\tval-merror:0.300375\n",
      "[4]\ttrain-merror:0.29713\tval-merror:0.300476\n",
      "[5]\ttrain-merror:0.296244\tval-merror:0.299767\n",
      "[6]\ttrain-merror:0.295864\tval-merror:0.299767\n",
      "[7]\ttrain-merror:0.296117\tval-merror:0.300274\n",
      "[8]\ttrain-merror:0.296244\tval-merror:0.298653\n",
      "[9]\ttrain-merror:0.295915\tval-merror:0.298653\n",
      "[10]\ttrain-merror:0.29556\tval-merror:0.298146\n",
      "[11]\ttrain-merror:0.295585\tval-merror:0.298146\n",
      "[12]\ttrain-merror:0.295636\tval-merror:0.298045\n",
      "[13]\ttrain-merror:0.295585\tval-merror:0.298653\n",
      "[14]\ttrain-merror:0.29518\tval-merror:0.298754\n",
      "[15]\ttrain-merror:0.295585\tval-merror:0.298653\n",
      "[16]\ttrain-merror:0.295509\tval-merror:0.298551\n",
      "[17]\ttrain-merror:0.295231\tval-merror:0.299058\n",
      "[18]\ttrain-merror:0.295003\tval-merror:0.299362\n",
      "[19]\ttrain-merror:0.294851\tval-merror:0.299666\n",
      "val loss  0.6805181023\n",
      "[0]\ttrain-merror:0.299435\tval-merror:0.301287\n",
      "[1]\ttrain-merror:0.299106\tval-merror:0.301084\n",
      "[2]\ttrain-merror:0.297966\tval-merror:0.299666\n",
      "[3]\ttrain-merror:0.297384\tval-merror:0.298754\n",
      "[4]\ttrain-merror:0.297358\tval-merror:0.298551\n",
      "[5]\ttrain-merror:0.297434\tval-merror:0.298653\n",
      "[6]\ttrain-merror:0.297206\tval-merror:0.298754\n",
      "[7]\ttrain-merror:0.297308\tval-merror:0.298551\n",
      "[8]\ttrain-merror:0.297181\tval-merror:0.298957\n",
      "[9]\ttrain-merror:0.296978\tval-merror:0.299058\n",
      "[10]\ttrain-merror:0.296953\tval-merror:0.299159\n",
      "[11]\ttrain-merror:0.29708\tval-merror:0.299058\n",
      "[12]\ttrain-merror:0.296345\tval-merror:0.298957\n",
      "[13]\ttrain-merror:0.295965\tval-merror:0.298653\n",
      "[14]\ttrain-merror:0.296193\tval-merror:0.298855\n",
      "[15]\ttrain-merror:0.295535\tval-merror:0.298855\n",
      "[16]\ttrain-merror:0.295357\tval-merror:0.298551\n",
      "[17]\ttrain-merror:0.295383\tval-merror:0.298349\n",
      "[18]\ttrain-merror:0.295535\tval-merror:0.298653\n",
      "[19]\ttrain-merror:0.295256\tval-merror:0.299058\n",
      "val loss  0.680880966709\n",
      "[0]\ttrain-merror:0.298878\tval-merror:0.300983\n",
      "[1]\ttrain-merror:0.298625\tval-merror:0.300476\n",
      "[2]\ttrain-merror:0.297814\tval-merror:0.299767\n",
      "[3]\ttrain-merror:0.297586\tval-merror:0.300071\n",
      "[4]\ttrain-merror:0.297409\tval-merror:0.29997\n",
      "[5]\ttrain-merror:0.296953\tval-merror:0.298957\n",
      "[6]\ttrain-merror:0.296826\tval-merror:0.298551\n",
      "[7]\ttrain-merror:0.297105\tval-merror:0.299058\n",
      "[8]\ttrain-merror:0.29675\tval-merror:0.298551\n",
      "[9]\ttrain-merror:0.296801\tval-merror:0.298957\n",
      "[10]\ttrain-merror:0.296649\tval-merror:0.298349\n",
      "[11]\ttrain-merror:0.296776\tval-merror:0.298855\n",
      "[12]\ttrain-merror:0.296472\tval-merror:0.298855\n",
      "[13]\ttrain-merror:0.296548\tval-merror:0.29926\n",
      "[14]\ttrain-merror:0.296472\tval-merror:0.299058\n",
      "[15]\ttrain-merror:0.29637\tval-merror:0.29845\n",
      "[16]\ttrain-merror:0.295053\tval-merror:0.299159\n",
      "[17]\ttrain-merror:0.295332\tval-merror:0.300274\n",
      "[18]\ttrain-merror:0.295104\tval-merror:0.299767\n",
      "[19]\ttrain-merror:0.294597\tval-merror:0.300881\n",
      "val loss  0.679475582607\n",
      "avg val loss 0.679475582607\n",
      "avg train loss 0.666941080515\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    val_losses = np.array([])\n",
    "    train_losses = np.array([])\n",
    "    X_train, y_train, X_test, y_test = subAndSample(subset, comp=True)\n",
    "    X_train, X_test = standardize(X_train, X_test)\n",
    "    dtrain = xgb.DMatrix(X_train, label= y_train)\n",
    "    dval = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "    # specify parameters via map\n",
    "    watchlist = [(dtrain,'train'), (dval,'val')]\n",
    "    param = {'max_depth':3, 'eta':1, 'silent':1, 'num_class': 3, 'objective':'multi:softprob' }\n",
    "    num_round = 20\n",
    "    bst = xgb.train(param, dtrain, num_round, watchlist)\n",
    "    preds = bst.predict(dval)\n",
    "    val_loss = log_loss(y_test, preds)\n",
    "    print('val loss ',val_loss)\n",
    "    train_loss = log_loss(y_train, bst.predict(dtrain))\n",
    "    train_losses = np.append(train_losses, train_loss)\n",
    "    val_losses = np.append(val_losses, val_loss)\n",
    "print('avg val loss', np.mean(val_losses))\n",
    "print('avg train loss', np.mean(train_losses))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['feat_str'] = train.features.apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "train_counts = count_vect.fit_transform(train.feat_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(train_counts)\n",
    "train_tf = tf_transformer.transform(train_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TfidfTransformer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_tf, train.enc_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1070"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = clf.predict_proba(train_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7584492522367966"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(train.enc_interest, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6948046685038094"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(train.enc_interest, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.691723229663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.76581763436551764"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = train[['feat_str', 'enc_interest']]\n",
    "X_train, X_test, y_train, y_test = subAndSample(subset, comp=True)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB())])\n",
    "\n",
    "X_train_concat = np.array(np.concatenate([a for a in X_train.values]))\n",
    "X_test_concat = np.array(np.concatenate([a for a in X_test.values]))\n",
    "\n",
    "text_clf.fit(X_train_concat, y_train.values)\n",
    "preds = text_clf.predict(X_test_concat)\n",
    "probs = text_clf.predict_proba(X_test_concat)\n",
    "print(get_accuracy(y_test, preds))\n",
    "log_loss(y_test,probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.693344139398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.76033893198013003"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = train[['feat_str', 'enc_interest']]\n",
    "X_train, X_test, y_train, y_test = subAndSample(subset, comp=True)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                      ('clf', MultinomialNB())])\n",
    "\n",
    "X_train_concat = np.array(np.concatenate([a for a in X_train.values]))\n",
    "X_test_concat = np.array(np.concatenate([a for a in X_test.values]))\n",
    "\n",
    "text_clf.fit(X_train_concat, y_train.values)\n",
    "preds = text_clf.predict(X_test_concat)\n",
    "probs = text_clf.predict_proba(X_test_concat)\n",
    "print(get_accuracy(y_test, preds))\n",
    "log_loss(y_test,probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.694154594266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.76523884493207528"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = train[['feat_str', 'enc_interest']]\n",
    "X_train, X_test, y_train, y_test = subAndSample(subset, comp=True)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                      ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                      ('clf', MultinomialNB())])\n",
    "\n",
    "X_train_concat = np.array(np.concatenate([a for a in X_train.values]))\n",
    "X_test_concat = np.array(np.concatenate([a for a in X_test.values]))\n",
    "\n",
    "text_clf.fit(X_train_concat, y_train.values)\n",
    "preds = text_clf.predict(X_test_concat)\n",
    "probs = text_clf.predict_proba(X_test_concat)\n",
    "print(get_accuracy(y_test, preds))\n",
    "log_loss(y_test,probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.692128457097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.79231916508995459"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = train[['feat_str', 'enc_interest']]\n",
    "X_train, X_test, y_train, y_test = subAndSample(subset, comp=True)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english', ngram_range=(1, 2))),\n",
    "                      ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                      ('clf', MultinomialNB())])\n",
    "\n",
    "X_train_concat = np.array(np.concatenate([a for a in X_train.values]))\n",
    "X_test_concat = np.array(np.concatenate([a for a in X_test.values]))\n",
    "\n",
    "text_clf.fit(X_train_concat, y_train.values)\n",
    "preds = text_clf.predict(X_test_concat)\n",
    "probs = text_clf.predict_proba(X_test_concat)\n",
    "print(get_accuracy(y_test, preds))\n",
    "log_loss(y_test,probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.695674197143\n",
      "0.696486917758\n"
     ]
    }
   ],
   "source": [
    "subset = train[['feat_str', 'enc_interest']]\n",
    "X_train, X_test, y_train, y_test = subAndSample(subset, comp=True)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english', ngram_range=(1, 2))),\n",
    "                      ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                      ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                            alpha=1e-4, n_iter=10)) ])\n",
    "\n",
    "X_train_concat = np.array(np.concatenate([a for a in X_train.values]))\n",
    "X_test_concat = np.array(np.concatenate([a for a in X_test.values]))\n",
    "\n",
    "text_clf.fit(X_train_concat, y_train.values)\n",
    "preds = text_clf.predict(X_test_concat)\n",
    "train_preds = text_clf.predict(X_train_concat)\n",
    "\n",
    "print(get_accuracy(y_test, preds))\n",
    "print(get_accuracy(y_train, train_preds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- split to train and test\n",
    "- fit svm on train\n",
    "- predict svm on test\n",
    "- add predictions as feature to classifier\n",
    "- get accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subset = train[['feat_str','bathrooms', 'bedrooms', 'price', 'enc_interest']]\n",
    "X_train, X_test, y_train, y_test = subAndSample(subset, comp=True)\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english', ngram_range=(1, 2))),\n",
    "                      ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                      ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                            alpha=1e-5, n_iter=5)) ])\n",
    "\n",
    "\n",
    "text_clf.fit(X_train.feat_str.values, y_train.values)\n",
    "\n",
    "preds = text_clf.predict(X_test.feat_str.values)\n",
    "\n",
    "train_preds = text_clf.predict(X_train.feat_str.values)\n",
    "\n",
    "X_test['svm_preds'] = preds\n",
    "X_train['svm_preds'] = train_preds\n",
    "\n",
    "X_train = X_train.drop('feat_str', axis=1)\n",
    "X_test= X_test.drop('feat_str', axis=1)\n",
    "\n",
    "X_train, X_test = standardize(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "lr.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69851078918\n",
      "0.722678949691\n"
     ]
    }
   ],
   "source": [
    "preds = lr.predict(X_test)\n",
    "probs = lr.predict_proba(X_test)\n",
    "print(get_accuracy(preds, y_test))\n",
    "\n",
    "\n",
    "print(log_loss(y_test, probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subset = train[['feat_str','bathrooms', 'bedrooms', 'price', 'enc_interest']]\n",
    "X_train, X_test, y_train, y_test = subAndSample(subset, comp=True)\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english', ngram_range=(1, 2))),\n",
    "                      ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                      ('clf', MultinomialNB())])\n",
    "\n",
    "\n",
    "text_clf.fit(X_train.feat_str.values, y_train.values)\n",
    "\n",
    "preds = text_clf.predict(X_test.feat_str.values)\n",
    "\n",
    "train_preds = text_clf.predict(X_train.feat_str.values)\n",
    "\n",
    "X_test['svm_preds'] = preds\n",
    "X_train['svm_preds'] = train_preds\n",
    "\n",
    "X_train = X_train.drop('feat_str', axis=1)\n",
    "X_test= X_test.drop('feat_str', axis=1)\n",
    "\n",
    "X_train, X_test = standardize(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "preds = lr.predict(X_test)\n",
    "\n",
    "print(get_accuracy(preds, y_test))\n",
    "\n",
    "get_accuracy(lr.predict(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.39618363e-01,  -4.36800222e-01,   5.95738072e-04,\n",
       "         -4.06530331e-01],\n",
       "       [  3.69696279e-02,   2.33803701e-03,   3.88956992e-05,\n",
       "          1.70429378e-01],\n",
       "       [  1.02648735e-01,   4.34462185e-01,  -6.34633771e-04,\n",
       "          2.36100953e-01]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "...                                            alpha=1e-3, n_iter=5, random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate text and regular matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_proc = Pipeline([('vect', CountVectorizer(ngram_range=(1, 3))),\n",
    "                      ('tfidf', TfidfTransformer(use_idf=True)) ])\n",
    "\n",
    "\n",
    "subset = train[['feat_str','bathrooms', 'bedrooms', 'price', 'enc_interest']]\n",
    "X_train, X_test, y_train, y_test = subAndSample(subset, comp=True)\n",
    "\n",
    "text_proc.fit(X_train.feat_str.values)\n",
    "\n",
    "tr_text_mat = text_proc.transform(X_train.feat_str.values)\n",
    "\n",
    "test_text_mat = text_proc.transform(X_test.feat_str.values)\n",
    "\n",
    "X_train =X_train.drop('feat_str', axis=1)\n",
    "X_test =X_test.drop('feat_str', axis=1)\n",
    "X_train, X_test = standardize(X_train, X_test)\n",
    "\n",
    "X_train_concat = scipy.sparse.hstack((X_train,tr_text_mat))\n",
    "\n",
    "X_test_concat = scipy.sparse.hstack((X_test, test_text_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.706716644717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.71573668346799724"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "lr.fit(X_train_concat, y_train)\n",
    "\n",
    "preds = lr.predict(X_test_concat)\n",
    "\n",
    "print(get_accuracy(preds, y_test))\n",
    "\n",
    "get_accuracy(lr.predict(X_train_concat), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Xgboost with concatenated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_proc = Pipeline([('vect', CountVectorizer(ngram_range=(1, 3))),\n",
    "                      ('tfidf', TfidfTransformer(use_idf=True)) ])\n",
    "\n",
    "\n",
    "subset = train[['feat_str','bathrooms', 'bedrooms', 'price', 'enc_interest']]\n",
    "X_train, X_test, y_train, y_test = subAndSample(subset, comp=True)\n",
    "\n",
    "text_proc.fit(X_train.feat_str.values)\n",
    "\n",
    "tr_text_mat = text_proc.transform(X_train.feat_str.values)\n",
    "\n",
    "test_text_mat = text_proc.transform(X_test.feat_str.values)\n",
    "\n",
    "X_train =X_train.drop('feat_str', axis=1)\n",
    "X_test =X_test.drop('feat_str', axis=1)\n",
    "X_train, X_test = standardize(X_train, X_test)\n",
    "\n",
    "X_train_concat = scipy.sparse.hstack((X_train,tr_text_mat))\n",
    "\n",
    "X_test_concat = scipy.sparse.hstack((X_test, test_text_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.294344\tval-merror:0.293385\n",
      "[1]\ttrain-merror:0.292622\tval-merror:0.292574\n",
      "[2]\ttrain-merror:0.289405\tval-merror:0.291764\n",
      "[3]\ttrain-merror:0.288189\tval-merror:0.291257\n",
      "[4]\ttrain-merror:0.285606\tval-merror:0.291662\n",
      "[5]\ttrain-merror:0.282237\tval-merror:0.289535\n",
      "[6]\ttrain-merror:0.281224\tval-merror:0.288927\n",
      "[7]\ttrain-merror:0.279856\tval-merror:0.288623\n",
      "[8]\ttrain-merror:0.279046\tval-merror:0.288623\n",
      "[9]\ttrain-merror:0.278286\tval-merror:0.288319\n",
      "[10]\ttrain-merror:0.277222\tval-merror:0.286901\n",
      "[11]\ttrain-merror:0.275044\tval-merror:0.286496\n",
      "[12]\ttrain-merror:0.274107\tval-merror:0.2868\n",
      "[13]\ttrain-merror:0.273524\tval-merror:0.286394\n",
      "[14]\ttrain-merror:0.272967\tval-merror:0.285989\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_train_concat, label= y_train)\n",
    "dval = xgb.DMatrix(X_test_concat, label=y_test)\n",
    "\n",
    "# specify parameters via map\n",
    "watchlist = [(dtrain,'train'), (dval,'val')]\n",
    "param = {'max_depth':3, 'eta':1, 'silent':1, 'num_class': 3, 'objective':'multi:softprob' }\n",
    "num_round = 15\n",
    "bst = xgb.train(param, dtrain, num_round, watchlist)\n",
    "\n",
    "preds = bst.predict(dval)\n",
    "\n",
    "print(log_loss(y_test, preds))\n",
    "\n",
    "log_loss(y_train, bst.predict(dtrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Settings that seem best so far:\n",
    "- use_idf =True\n",
    "- no stopwords\n",
    "- ngram range 2 or 3\n",
    "\n",
    "Xgboost on text features concatenated with regular features seems like the way to go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_proc = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2))),\n",
    "                      ('tfidf', TfidfTransformer(use_idf=True)) ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subset = train[['description','bathrooms', 'bedrooms', 'price', 'enc_interest']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = subAndSample(subset, comp=True)\n",
    "\n",
    "text_proc.fit(X_train.description.values)\n",
    "\n",
    "tr_text_mat = text_proc.transform(X_train.description.values)\n",
    "\n",
    "test_text_mat = text_proc.transform(X_test.description.values)\n",
    "\n",
    "X_train =X_train.drop('description', axis=1)\n",
    "X_test =X_test.drop('description', axis=1)\n",
    "X_train, X_test = standardize(X_train, X_test)\n",
    "\n",
    "X_train_concat = scipy.sparse.hstack((X_train,tr_text_mat))\n",
    "\n",
    "X_test_concat = scipy.sparse.hstack((X_test, test_text_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.297688\tval-merror:0.294803\n",
      "[1]\ttrain-merror:0.295307\tval-merror:0.295715\n",
      "[2]\ttrain-merror:0.293584\tval-merror:0.29612\n",
      "[3]\ttrain-merror:0.28943\tval-merror:0.294803\n",
      "[4]\ttrain-merror:0.285758\tval-merror:0.293283\n",
      "[5]\ttrain-merror:0.284162\tval-merror:0.293081\n",
      "[6]\ttrain-merror:0.283174\tval-merror:0.29146\n",
      "[7]\ttrain-merror:0.279628\tval-merror:0.292676\n",
      "[8]\ttrain-merror:0.277551\tval-merror:0.290852\n",
      "[9]\ttrain-merror:0.275474\tval-merror:0.289535\n",
      "[10]\ttrain-merror:0.272764\tval-merror:0.288623\n",
      "[11]\ttrain-merror:0.2717\tval-merror:0.287813\n",
      "[12]\ttrain-merror:0.269978\tval-merror:0.28913\n",
      "[13]\ttrain-merror:0.268154\tval-merror:0.288826\n",
      "[14]\ttrain-merror:0.264887\tval-merror:0.287711\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_train_concat, label= y_train)\n",
    "dval = xgb.DMatrix(X_test_concat, label=y_test)\n",
    "\n",
    "# specify parameters via map\n",
    "watchlist = [(dtrain,'train'), (dval,'val')]\n",
    "param = {'max_depth':3, 'eta':1, 'silent':1, 'num_class': 3, 'objective':'multi:softprob' }\n",
    "num_round = 15\n",
    "bst = xgb.train(param, dtrain, num_round, watchlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.664866422157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6263888617674026"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = bst.predict(dval)\n",
    "print(log_loss(y_test, preds))\n",
    "log_loss(y_train, bst.predict(dtrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features and Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_proc_feat = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2))),\n",
    "                      ('tfidf', TfidfTransformer(use_idf=True)) ])\n",
    "text_proc_desc = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2))),\n",
    "                      ('tfidf', TfidfTransformer(use_idf=True)) ])\n",
    "\n",
    "\n",
    "subset = train[['feat_str', 'description', 'bathrooms', 'bedrooms', 'price', 'enc_interest']]\n",
    "X_train, X_test, y_train, y_test = subAndSample(subset, comp=True)\n",
    "\n",
    "\n",
    "\n",
    "text_proc_feat.fit(X_train.feat_str.values)\n",
    "tr_feat_text = text_proc.transform(X_train.feat_str.values)\n",
    "test_feat_text = text_proc.transform(X_test.feat_str.values)\n",
    "\n",
    "\n",
    "text_proc_desc.fit(X_train.description.values)\n",
    "tr_desc_mat = text_proc_desc.transform(X_train.description.values)\n",
    "test_desc_mat = text_proc_desc.transform(X_test.description.values)\n",
    "\n",
    "\n",
    "X_train = X_train.drop(['feat_str', 'description'], axis=1)\n",
    "X_test = X_test.drop(['feat_str', 'description'], axis=1)\n",
    "X_train, X_test = standardize(X_train, X_test)\n",
    "\n",
    "\n",
    "X_train_concat = scipy.sparse.hstack((X_train,tr_feat_text, tr_desc_mat))\n",
    "X_test_concat = scipy.sparse.hstack((X_test, test_feat_text, test_desc_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.294952\tval-merror:0.294296\n",
      "[1]\ttrain-merror:0.293534\tval-merror:0.293283\n",
      "[2]\ttrain-merror:0.291431\tval-merror:0.291865\n",
      "[3]\ttrain-merror:0.286416\tval-merror:0.289738\n",
      "[4]\ttrain-merror:0.283655\tval-merror:0.287813\n",
      "[5]\ttrain-merror:0.276817\tval-merror:0.285179\n",
      "[6]\ttrain-merror:0.274157\tval-merror:0.28295\n",
      "[7]\ttrain-merror:0.27127\tval-merror:0.282646\n",
      "[8]\ttrain-merror:0.268965\tval-merror:0.282747\n",
      "[9]\ttrain-merror:0.26742\tval-merror:0.280215\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_train_concat, label= y_train)\n",
    "dval = xgb.DMatrix(X_test_concat, label=y_test)\n",
    "\n",
    "# specify parameters via map\n",
    "watchlist = [(dtrain,'train'), (dval,'val')]\n",
    "param = {'max_depth':3, 'eta':1, 'silent':1, 'num_class': 3, 'objective':'multi:softprob' }\n",
    "num_round = 10\n",
    "bst = xgb.train(param, dtrain, num_round, watchlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.644885487823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6205642350065651"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = bst.predict(dval)\n",
    "print(log_loss(y_test, preds))\n",
    "log_loss(y_train, bst.predict(dtrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.294952\tval-merror:0.294296\n",
      "[1]\ttrain-merror:0.293534\tval-merror:0.293283\n",
      "[2]\ttrain-merror:0.291431\tval-merror:0.291865\n",
      "[3]\ttrain-merror:0.286416\tval-merror:0.289738\n",
      "[4]\ttrain-merror:0.283655\tval-merror:0.287813\n",
      "[5]\ttrain-merror:0.276817\tval-merror:0.285179\n",
      "[6]\ttrain-merror:0.274157\tval-merror:0.28295\n",
      "[7]\ttrain-merror:0.27127\tval-merror:0.282646\n",
      "[8]\ttrain-merror:0.268965\tval-merror:0.282747\n",
      "[9]\ttrain-merror:0.26742\tval-merror:0.280215\n",
      "[10]\ttrain-merror:0.26514\tval-merror:0.280924\n",
      "[11]\ttrain-merror:0.263646\tval-merror:0.280417\n",
      "[12]\ttrain-merror:0.261645\tval-merror:0.280113\n",
      "[13]\ttrain-merror:0.259365\tval-merror:0.277378\n",
      "[14]\ttrain-merror:0.25744\tval-merror:0.276872\n"
     ]
    }
   ],
   "source": [
    "param = {'max_depth':3, 'eta':1, 'silent':1, 'num_class': 3, 'objective':'multi:softprob' }\n",
    "num_round = 15\n",
    "bst = xgb.train(param, dtrain, num_round, watchlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.63915561909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6025585486170203"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = bst.predict(dval)\n",
    "print(log_loss(y_test, preds))\n",
    "log_loss(y_train, bst.predict(dtrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.294952\tval-merror:0.294296\n",
      "[1]\ttrain-merror:0.293534\tval-merror:0.293283\n",
      "[2]\ttrain-merror:0.291431\tval-merror:0.291865\n",
      "[3]\ttrain-merror:0.286416\tval-merror:0.289738\n",
      "[4]\ttrain-merror:0.283655\tval-merror:0.287813\n",
      "[5]\ttrain-merror:0.276817\tval-merror:0.285179\n",
      "[6]\ttrain-merror:0.274157\tval-merror:0.28295\n",
      "[7]\ttrain-merror:0.27127\tval-merror:0.282646\n",
      "[8]\ttrain-merror:0.268965\tval-merror:0.282747\n",
      "[9]\ttrain-merror:0.26742\tval-merror:0.280215\n",
      "[10]\ttrain-merror:0.26514\tval-merror:0.280924\n",
      "[11]\ttrain-merror:0.263646\tval-merror:0.280417\n",
      "[12]\ttrain-merror:0.261645\tval-merror:0.280113\n",
      "[13]\ttrain-merror:0.259365\tval-merror:0.277378\n",
      "[14]\ttrain-merror:0.25744\tval-merror:0.276872\n",
      "[15]\ttrain-merror:0.256123\tval-merror:0.276264\n",
      "[16]\ttrain-merror:0.254831\tval-merror:0.274643\n",
      "[17]\ttrain-merror:0.252982\tval-merror:0.274339\n",
      "[18]\ttrain-merror:0.251159\tval-merror:0.274643\n",
      "[19]\ttrain-merror:0.249842\tval-merror:0.274643\n",
      "[20]\ttrain-merror:0.24893\tval-merror:0.274238\n",
      "[21]\ttrain-merror:0.246473\tval-merror:0.274643\n",
      "[22]\ttrain-merror:0.245232\tval-merror:0.275453\n",
      "[23]\ttrain-merror:0.244295\tval-merror:0.276163\n",
      "[24]\ttrain-merror:0.24351\tval-merror:0.276365\n"
     ]
    }
   ],
   "source": [
    "param = {'max_depth':3, 'eta':1, 'silent':1, 'num_class': 3, 'objective':'multi:softprob' }\n",
    "num_round = 25\n",
    "bst = xgb.train(param, dtrain, num_round, watchlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.634272339866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5737917812620611"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = bst.predict(dval)\n",
    "print(log_loss(y_test, preds))\n",
    "log_loss(y_train, bst.predict(dtrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.294952\tval-merror:0.294296\n",
      "[1]\ttrain-merror:0.293534\tval-merror:0.293283\n",
      "[2]\ttrain-merror:0.291431\tval-merror:0.291865\n",
      "[3]\ttrain-merror:0.286416\tval-merror:0.289738\n",
      "[4]\ttrain-merror:0.283655\tval-merror:0.287813\n",
      "[5]\ttrain-merror:0.276817\tval-merror:0.285179\n",
      "[6]\ttrain-merror:0.274157\tval-merror:0.28295\n",
      "[7]\ttrain-merror:0.27127\tval-merror:0.282646\n",
      "[8]\ttrain-merror:0.268965\tval-merror:0.282747\n",
      "[9]\ttrain-merror:0.26742\tval-merror:0.280215\n",
      "[10]\ttrain-merror:0.26514\tval-merror:0.280924\n",
      "[11]\ttrain-merror:0.263646\tval-merror:0.280417\n",
      "[12]\ttrain-merror:0.261645\tval-merror:0.280113\n",
      "[13]\ttrain-merror:0.259365\tval-merror:0.277378\n",
      "[14]\ttrain-merror:0.25744\tval-merror:0.276872\n",
      "[15]\ttrain-merror:0.256123\tval-merror:0.276264\n",
      "[16]\ttrain-merror:0.254831\tval-merror:0.274643\n",
      "[17]\ttrain-merror:0.252982\tval-merror:0.274339\n",
      "[18]\ttrain-merror:0.251159\tval-merror:0.274643\n",
      "[19]\ttrain-merror:0.249842\tval-merror:0.274643\n",
      "[20]\ttrain-merror:0.24893\tval-merror:0.274238\n",
      "[21]\ttrain-merror:0.246473\tval-merror:0.274643\n",
      "[22]\ttrain-merror:0.245232\tval-merror:0.275453\n",
      "[23]\ttrain-merror:0.244295\tval-merror:0.276163\n",
      "[24]\ttrain-merror:0.24351\tval-merror:0.276365\n",
      "[25]\ttrain-merror:0.242344\tval-merror:0.276973\n",
      "[26]\ttrain-merror:0.240951\tval-merror:0.277986\n",
      "[27]\ttrain-merror:0.24004\tval-merror:0.277074\n",
      "[28]\ttrain-merror:0.237329\tval-merror:0.274643\n",
      "[29]\ttrain-merror:0.236468\tval-merror:0.273934\n",
      "[30]\ttrain-merror:0.235556\tval-merror:0.273427\n",
      "[31]\ttrain-merror:0.23505\tval-merror:0.273934\n",
      "[32]\ttrain-merror:0.233834\tval-merror:0.27444\n",
      "[33]\ttrain-merror:0.232365\tval-merror:0.276264\n",
      "[34]\ttrain-merror:0.231732\tval-merror:0.276568\n",
      "[35]\ttrain-merror:0.230795\tval-merror:0.277986\n",
      "[36]\ttrain-merror:0.22968\tval-merror:0.278493\n",
      "[37]\ttrain-merror:0.228718\tval-merror:0.27829\n",
      "[38]\ttrain-merror:0.227806\tval-merror:0.2791\n",
      "[39]\ttrain-merror:0.226767\tval-merror:0.278594\n",
      "[40]\ttrain-merror:0.226109\tval-merror:0.278999\n",
      "[41]\ttrain-merror:0.224842\tval-merror:0.279607\n",
      "[42]\ttrain-merror:0.223728\tval-merror:0.279708\n",
      "[43]\ttrain-merror:0.222968\tval-merror:0.2791\n",
      "[44]\ttrain-merror:0.222082\tval-merror:0.278493\n",
      "[45]\ttrain-merror:0.221195\tval-merror:0.278493\n",
      "[46]\ttrain-merror:0.219295\tval-merror:0.278493\n",
      "[47]\ttrain-merror:0.218561\tval-merror:0.279607\n",
      "[48]\ttrain-merror:0.217497\tval-merror:0.278493\n",
      "[49]\ttrain-merror:0.216737\tval-merror:0.278695\n",
      "[50]\ttrain-merror:0.215952\tval-merror:0.278999\n",
      "[51]\ttrain-merror:0.215217\tval-merror:0.27829\n",
      "[52]\ttrain-merror:0.214559\tval-merror:0.27829\n",
      "[53]\ttrain-merror:0.213495\tval-merror:0.278695\n",
      "[54]\ttrain-merror:0.213065\tval-merror:0.27829\n"
     ]
    }
   ],
   "source": [
    "param = {'max_depth':3, 'eta':1, 'silent':1, 'num_class': 3, 'objective':'multi:softprob' }\n",
    "num_round = 55\n",
    "bst = xgb.train(param, dtrain, num_round, watchlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.634050668408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.51333511762367889"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = bst.predict(dval)\n",
    "print(log_loss(y_test, preds))\n",
    "log_loss(y_train, bst.predict(dtrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Val Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgbc = XGBClassifier(objective='multiclass:softprob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgbc.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_proc_feat = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2))),\n",
    "                      ('tfidf', TfidfTransformer(use_idf=True)) ])\n",
    "text_proc_desc = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2))),\n",
    "                      ('tfidf', TfidfTransformer(use_idf=True)) ])\n",
    "\n",
    "\n",
    "subset = train[['feat_str', 'description', 'bathrooms', 'bedrooms', 'price', 'enc_interest']]\n",
    "X_train, y_train, X_test, y_test = subAndSample(subset, num_train=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_proc_feat.fit(X_train.feat_str.values)\n",
    "tr_feat_text = text_proc.transform(X_train.feat_str.values)\n",
    "\n",
    "\n",
    "\n",
    "text_proc_desc.fit(X_train.description.values)\n",
    "tr_desc_mat = text_proc_desc.transform(X_train.description.values)\n",
    "\n",
    "X_train = X_train.drop(['feat_str', 'description'], axis=1)\n",
    "\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "\n",
    "\n",
    "X_train_concat = scipy.sparse.hstack((X_train,tr_feat_text, tr_desc_mat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs = GridSearchCV(estimator=XGBClassifier(objective='multiclass:softprob'), param_grid=params, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] max_depth=2 .....................................................\n",
      "[CV] ............................ max_depth=2, score=0.688623 -  51.5s\n",
      "[CV] max_depth=2 .....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   51.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ max_depth=2, score=0.698198 -  49.8s\n",
      "[CV] max_depth=2 .....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ max_depth=2, score=0.692192 -  49.6s\n",
      "[CV] max_depth=4 .....................................................\n",
      "[CV] ............................ max_depth=4, score=0.687126 - 1.0min\n",
      "[CV] max_depth=4 .....................................................\n",
      "[CV] ............................ max_depth=4, score=0.707207 - 1.0min\n",
      "[CV] max_depth=4 .....................................................\n",
      "[CV] ............................ max_depth=4, score=0.686186 - 1.1min\n",
      "[CV] max_depth=6 .....................................................\n",
      "[CV] ............................ max_depth=6, score=0.685629 - 1.3min\n",
      "[CV] max_depth=6 .....................................................\n",
      "[CV] ............................ max_depth=6, score=0.695195 - 1.2min\n",
      "[CV] max_depth=6 .....................................................\n",
      "[CV] ............................ max_depth=6, score=0.675676 - 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  9.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='multiclass:softprob', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [2, 4, 6]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, scoring=None, verbose=3)"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train_concat, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'max_depth':[6,8,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs = GridSearchCV(estimator=XGBClassifier(objective='multiclass:softprob'), param_grid=params, verbose=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['address_lower'] = train.display_address.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8630"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.address_lower.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "addr = train.groupby('address_lower').enc_interest.count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24450"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addr[:300].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "addr_df = pd.DataFrame(np.zeros((train.shape[0],50)), index=train.index, columns = addr.index.values[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_ops = train.shape[0] * 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2467600"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for r,v in train.iterrows():\n",
    "    i+=1\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    for col in addr_df.columns:\n",
    "        if v[-1] == col:\n",
    "            addr_df.loc[r,col] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "addr_sparse = scipy.sparse.csr_matrix(addr_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_concat = pd.concat([train, addr_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_concat = train.concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bathrooms', 'bedrooms', 'building_id', 'created', 'description',\n",
       "       'display_address', 'features', 'interest_level', 'latitude',\n",
       "       'listing_id', 'longitude', 'manager_id', 'photos', 'price',\n",
       "       'street_address', 'enc_interest', 'feat_str', 'address_lower'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns\n",
    "\n",
    "to_drop = ['building_id', 'created', 'description',\n",
    "       'display_address', 'features', 'interest_level', 'latitude',\n",
    "       'listing_id', 'longitude', 'manager_id', 'photos', 'street_address', 'feat_str', 'address_lower']\n",
    "\n",
    "train_concat = train_concat.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49352, 54)"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subset= train[['bathrooms', 'bedrooms', 'price','enc_interest', 'address_lower']]\n",
    "\n",
    "X_train, y_train, X_test, y_test = subAndSample(subset, comp=True)\n",
    "\n",
    "h = FeatureHasher(input_type='string')\n",
    "\n",
    "hashed = h.fit_transform(X_train.address_lower)\n",
    "\n",
    "\n",
    "test_hashed = h.transform(X_test.address_lower)\n",
    "\n",
    "X_train = X_train.drop('address_lower', axis=1)\n",
    "X_test = X_test.drop('address_lower', axis=1)\n",
    "\n",
    "X_train, X_test = standardize(X_train, X_test)\n",
    "\n",
    "X_train_concat = scipy.sparse.hstack((X_train,hashed))\n",
    "\n",
    "X_test_concat = scipy.sparse.hstack((X_test, test_hashed))\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train_concat, label= y_train)\n",
    "dval = xgb.DMatrix(X_test_concat, label=y_test)\n",
    "\n",
    "# specify parameters via map\n",
    "watchlist = [(dtrain,'train'), (dval,'val')]\n",
    "param = {'max_depth':3, 'eta':1, 'silent':1, 'num_class': 3, 'objective':'multi:softprob' }\n",
    "num_round = 20\n",
    "bst = xgb.train(param, dtrain, num_round, watchlist)\n",
    "\n",
    "\n",
    "preds = bst.predict(dval)\n",
    "print(log_loss(y_test, preds))\n",
    "log_loss(y_train, bst.predict(dtrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
